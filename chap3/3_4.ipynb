{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled45.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPhb8tLlQkSxZZwCdCkoaYZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaos44/generative_deep_learning/blob/main/chap3/3_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL0g3wK2dcAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "591fb351-68bc-4b30-e2ae-99d1324c4ffa"
      },
      "source": [
        "!git clone -b tensorflow_2 https://github.com/davidADSP/GDL_code.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'GDL_code' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymD3Tuyl4noI",
        "outputId": "da707737-c64b-4e41-9158-7c12236fa81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting absl-py==0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n",
            "\r\u001b[K     |███▏                            | 10kB 23.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 20kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 30kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 40kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 51kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 61kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 81kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 92kB 10.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 102kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 8.0MB/s \n",
            "\u001b[?25hCollecting appnope==0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/87/a9/7985e6a53402f294c8f0e8eff3151a83f1fb901fa92909bb3ff29b4d22af/appnope-0.1.0-py2.py3-none-any.whl\n",
            "Collecting astor==0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.6.3)\n",
            "Collecting attrs==19.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/e8/2ecaf86b128a34e225807f03b22664302937ab826bd3b7eccab6754d29ea/attrs-19.2.0-py2.py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 6.8MB/s \n",
            "\u001b[?25hCollecting backcall==0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/84/71/c8ca4f5bb1e08401b916c68003acf0a0655df935d74d93bf3f3364b310e0/backcall-0.1.0.tar.gz\n",
            "Collecting bleach==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/05/27e1466475e816d3001efb6e0a85a819be17411420494a1e602c36f8299d/bleach-3.1.0-py2.py3-none-any.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools==4.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (4.1.1)\n",
            "Requirement already satisfied: certifi==2020.6.20 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (2020.6.20)\n",
            "Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (3.0.4)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.10.0)\n",
            "Collecting decorator==4.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: defusedxml==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (0.6.0)\n",
            "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (0.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (0.3.3)\n",
            "Collecting google-auth==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/57/d706964a7e4056f3f2244e16705388c11631fbb53d3e2d2a2d0fbc24d470/google_auth-1.18.0-py2.py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.4MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib==0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (0.2.0)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (2.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (2.10)\n",
            "Collecting imageio==2.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/de/f7f985018f462ceeffada7f6e609919fbcc934acd9301929cba14bc2c24a/imageio-2.6.1-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 13.5MB/s \n",
            "\u001b[?25hCollecting importlib-metadata==0.23\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/d2/40b3fa882147719744e6aa50ac39cf7a22a913cbcba86a0371176c425a3b/importlib_metadata-0.23-py2.py3-none-any.whl\n",
            "Collecting ipykernel==5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/16/43f51f65a8a08addf04f909a0938b06ba1ee1708b398a9282474531bd893/ipykernel-5.1.2-py3-none-any.whl (116kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 51.5MB/s \n",
            "\u001b[?25hCollecting ipython==7.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/44/f28a13852e562af719f9de1761680a84a93e8b4c50e22d00d68f60ee2e8b/ipython-7.8.0-py3-none-any.whl (775kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 25)) (0.2.0)\n",
            "Requirement already satisfied: ipywidgets==7.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 26)) (7.5.1)\n",
            "Collecting jedi==0.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/54/da994f359e4e7da4776a200e76dbc85ba5fc319eefc22e33d55296d95a1d/jedi-0.15.1-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 22.8MB/s \n",
            "\u001b[?25hCollecting Jinja2==2.10.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/e0/eb35e762802015cab1ccee04e8a277b03f1d8e53da3ec3106882ec42558b/Jinja2-2.10.3-py2.py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.9MB/s \n",
            "\u001b[?25hCollecting jsonschema==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/6c/888d7c3c1fce3974c88a01a6bc553528c99d3586e098eee23e8383dd11c3/jsonschema-3.1.1-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 30)) (1.0.0)\n",
            "Collecting jupyter-client==5.3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/81/fe0eee1bcf949851a120254b1f530ae1e01bdde2d3ab9710c6ff81525061/jupyter_client-5.3.4-py2.py3-none-any.whl (92kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.7MB/s \n",
            "\u001b[?25hCollecting jupyter-console==6.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/ee/6374ae8c21b7d0847f9c3722dcdfac986b8e54fa9ad9ea66e1eb6320d2b8/jupyter_console-6.0.0-py2.py3-none-any.whl\n",
            "Collecting jupyter-core==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a6/fe4b7029d4994870df6685bdc7bae5417bea30b627c4ce36106f9cac31fc/jupyter_core-4.6.0-py2.py3-none-any.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 14.2MB/s \n",
            "\u001b[?25hCollecting Keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 51.7MB/s \n",
            "\u001b[?25hCollecting Keras-Applications==1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[?25hCollecting Keras-Preprocessing==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[?25hCollecting kiwisolver==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/a1/5742b56282449b1c0968197f63eae486eca2c35dcd334bab75ad524e0de1/kiwisolver-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.4MB/s \n",
            "\u001b[?25hCollecting Markdown==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 14.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 39)) (1.1.1)\n",
            "Collecting matplotlib==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/4f/dd381ecf6c6ab9bcdaa8ea912e866dedc6e696756156d8ecc087e20817e2/matplotlib-3.1.1-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1MB 251kB/s \n",
            "\u001b[?25hRequirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 41)) (0.8.4)\n",
            "Collecting more-itertools==7.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/dc/3241eef99eb45f1def35cf93af35d1cf9ef4c0991792583b8f33ea41b092/more_itertools-7.2.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.6MB/s \n",
            "\u001b[?25hCollecting music21==5.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/38/ad81475627931c575f33071ff11a87f0a531b49e31ec5801a57264652bc4/music21-5.7.0.tar.gz (18.5MB)\n",
            "\u001b[K     |████████████████████████████████| 18.5MB 176kB/s \n",
            "\u001b[?25hCollecting nbconvert==5.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/df/4505c0a7fea624cac461d0f41051f33456ae656753f65cee8c2f43121cb2/nbconvert-5.6.0-py2.py3-none-any.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 47.6MB/s \n",
            "\u001b[?25hCollecting nbformat==4.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/27/9a654d2b6cc1eaa517d1c5a4405166c7f6d72f04f6e7eea41855fe808a46/nbformat-4.4.0-py2.py3-none-any.whl (155kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 57.2MB/s \n",
            "\u001b[?25hCollecting networkx==2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 46.0MB/s \n",
            "\u001b[?25hCollecting notebook==6.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/a1/1e07cedcb554408fefe4a7d32b2a041c86517167aec6ca8251c808ef6c1e/notebook-6.0.1-py3-none-any.whl (9.0MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0MB 44.7MB/s \n",
            "\u001b[?25hCollecting numpy==1.17.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/e6/c3fdc53aed9fa19d6ff3abf97dfad768ae3afce1b7431f7500000816bda5/numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
            "\u001b[K     |████████████████████████████████| 20.4MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 49)) (3.1.0)\n",
            "Collecting opt-einsum==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.1MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/9b/52e228545d14f14bb2a1622e225f38463c8726645165e1cb7dde95bfe6d4/pandas-0.25.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5MB 29.4MB/s \n",
            "\u001b[?25hCollecting pandocfilters==1.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/ea/236e2584af67bb6df960832731a6e5325fd4441de001767da328c33368ce/pandocfilters-1.4.2.tar.gz\n",
            "Collecting parso==0.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/bd/bf4e5bd01d79906e5b945a7af033154da49fd2b0d5b5c705a21330323305/parso-0.5.1-py2.py3-none-any.whl (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.9MB/s \n",
            "\u001b[?25hCollecting pexpect==4.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/3e/377007e3f36ec42f1b84ec322ee12141a9e10d808312e5738f52f80a232c/pexpect-4.7.0-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 55)) (0.7.5)\n",
            "Collecting Pillow==6.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/66/6113477dc3206ccb1e192cffd626f2840ead02375a6cebe2436ad4c19f61/Pillow-6.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 53.1MB/s \n",
            "\u001b[?25hCollecting prometheus-client==0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/23/41a5a24b502d35a4ad50a5bb7202a5e1d9a0364d0c12f56db3dbf7aca76d/prometheus_client-0.7.1.tar.gz\n",
            "Collecting prompt-toolkit==2.0.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/61/2dfea88583d5454e3a64f9308a686071d58d59a55db638268a6413e1eb6d/prompt_toolkit-2.0.10-py3-none-any.whl (340kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 51.8MB/s \n",
            "\u001b[?25hCollecting protobuf==3.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/52/d8d2dbff74b8bf517c42db8d44c3f9ef6555e6f5d6caddfa3f207b9143df/protobuf-3.10.0-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: ptyprocess==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 60)) (0.6.0)\n",
            "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 61)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 62)) (0.2.8)\n",
            "Collecting pydot==1.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pydotplus==2.0.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 64)) (2.0.2)\n",
            "Collecting Pygments==2.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/73/1dfa428150e3ccb0fa3e68db406e5be48698f2a979ccbcec795f28f44048/Pygments-2.4.2-py2.py3-none-any.whl (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 46.4MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/fa/0160cd525c62d7abd076a070ff02b2b94de589f1a9789774f17d7c54058e/pyparsing-2.4.2-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
            "\u001b[?25hCollecting pyrsistent==0.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/66/b2638d96a2d128b168d0dba60fdc77b7800a9b4a5340cefcc5fc4eae6295/pyrsistent-0.15.4.tar.gz (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 63.3MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 51.2MB/s \n",
            "\u001b[?25hCollecting pytz==2019.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 46.9MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 50.3MB/s \n",
            "\u001b[?25hCollecting pyzmq==18.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/89/6f0ea51ffa9c2c00c0ab0460f137b16a5ab5b47e3b060c5b1fc9ca425836/pyzmq-18.1.0-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 46.5MB/s \n",
            "\u001b[?25hCollecting qtconsole==4.5.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/fc/4936c60be8d56acedfefcc13cf9f3d881e4036147d78e86160463c92d1b7/qtconsole-4.5.5-py2.py3-none-any.whl (121kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 51.7MB/s \n",
            "\u001b[?25hCollecting requests==2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 74)) (1.3.0)\n",
            "Requirement already satisfied: rsa==4.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 75)) (4.6)\n",
            "Collecting scikit-image==0.17.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/ba/53e1bfbdfd0f94514d71502e3acea494a8b4b57c457adbc333ef386485da/scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4MB 263kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 77)) (1.4.1)\n",
            "Requirement already satisfied: Send2Trash==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 78)) (1.5.0)\n",
            "Collecting six==1.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Collecting tensorboard==2.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit==1.7.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 81)) (1.7.0)\n",
            "Collecting tensorflow==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 33kB/s \n",
            "\u001b[?25hCollecting tensorflow-addons==0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/ce/ed8472bf2b93b53702f28d91caee52181f7a10bee6eec0617a71dea12fa6/tensorflow_addons-0.10.0-cp36-cp36m-manylinux2010_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 30kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 46.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 85)) (1.1.0)\n",
            "Collecting terminado==0.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/56/80ea7fa66565fa75ae21ce0c16bc90067530e5d15e48854afcc86585a391/terminado-0.8.2-py2.py3-none-any.whl\n",
            "Collecting testpath==0.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/a4/162f9ebb6489421fe46dcca2ae420369edfee4b563c668d93cb4605d12ba/testpath-0.4.2-py2.py3-none-any.whl (163kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 57.0MB/s \n",
            "\u001b[?25hCollecting tornado==6.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/78/2d2823598496127b21423baffaa186b668f73cd91887fcef78b6eade136b/tornado-6.0.3.tar.gz (482kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets==4.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 89)) (4.3.3)\n",
            "Collecting typeguard==2.9.1\n",
            "  Downloading https://files.pythonhosted.org/packages/52/33/3755584541a18d954389447bfd5f9cb7fa20dfbf5094829aee4a103e580c/typeguard-2.9.1-py3-none-any.whl\n",
            "Collecting urllib3==1.25.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 52.3MB/s \n",
            "\u001b[?25hCollecting wcwidth==0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/9f/526a6947247599b084ee5232e4f9190a38f398d7300d866af3ab571a5bfe/wcwidth-0.1.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 93)) (0.5.1)\n",
            "Collecting Werkzeug==0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 55.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: widgetsnbextension==3.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 95)) (3.5.1)\n",
            "Collecting wrapt==1.11.2\n",
            "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
            "Collecting zipp==0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/74/3d/1ee25a26411ba0401b43c6376d2316a71addcc72ef8690b101b4ea56d76a/zipp-0.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from astunparse==1.6.3->-r requirements.txt (line 4)) (0.35.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth==1.18.0->-r requirements.txt (line 16)) (50.3.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.17.2->-r requirements.txt (line 76)) (2020.9.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.17.2->-r requirements.txt (line 76)) (1.1.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.2->-r requirements.txt (line 80)) (1.33.2)\n",
            "Building wheels for collected packages: absl-py, backcall, music21, networkx, opt-einsum, pandocfilters, prometheus-client, pyrsistent, PyYAML, tornado, wrapt\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.8.1-cp36-none-any.whl size=121167 sha256=b63068a4fd9b0a97003bd36e4cff9e07b5031341423c261e74c36b8fc6a69093\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n",
            "  Building wheel for backcall (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for backcall: filename=backcall-0.1.0-cp36-none-any.whl size=10413 sha256=10b74d4c3c1d6a19f3b7da115c1baa7a4d94eccb2d1d614d6b0aede22cd24bb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/b0/dd/29e28ff615af3dda4c67cab719dd51357597eabff926976b45\n",
            "  Building wheel for music21 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for music21: filename=music21-5.7.0-cp36-none-any.whl size=22075010 sha256=1437b09aa959799ba31a6a60572f1845a93b458dcd24182e3bab6285f4fd4ade\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/d4/20/c3f5d8717f440d1b9efcb56aafcef71902b13e752ab102ea2c\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556409 sha256=33de1bfb45763c12cc8c33bd0159598ac2c6dc7ae90189b19f0bb5f7bf92d85c\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-cp36-none-any.whl size=61682 sha256=cf875b734c36f923b16e90e03495531d64d36285fd813baa590f1a06bd8c3c72\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
            "  Building wheel for pandocfilters (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandocfilters: filename=pandocfilters-1.4.2-cp36-none-any.whl size=7857 sha256=8552aefad676428242a93b2dac2813ff14ad8c616c28d3778ad521cfd34e3063\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/01/56/f1b08a6275acc59e846fa4c1e1b65dbc1919f20157d9e66c20\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-cp36-none-any.whl size=41403 sha256=5b3600953533199d8046aaab5b618d2a7bc87b143a303853a0fe6c9c837b4bd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/54/34/fd47cd9b308826cc4292b54449c1899a30251ef3b506bc91ea\n",
            "  Building wheel for pyrsistent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrsistent: filename=pyrsistent-0.15.4-cp36-cp36m-linux_x86_64.whl size=97549 sha256=251319e0682649713228ec376d1fb5def945bd134d09cbc3f8609a24c4e272a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/46/00/6d471ef0b813e3621f0abe6cb723c20d529d39a061de3f7c51\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44103 sha256=c90bf5796af689a9e833b80db49fe5a8c11ea1db5f5fdb79320467a92bd2c40f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-6.0.3-cp36-cp36m-linux_x86_64.whl size=423186 sha256=54999f549cc310a2210cf19a8f5d74310667864105fd1c12d1cf4c9f74c68f77\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/bf/40/2f6ef700f48401ca40e5e3dd7d0e3c0a90e064897b7fe5fc08\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl size=67531 sha256=1661b076e936ae5930fa2eaba60f1bc262de2e475fb0f947fe0d97175ae3a2d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
            "Successfully built absl-py backcall music21 networkx opt-einsum pandocfilters prometheus-client pyrsistent PyYAML tornado wrapt\n",
            "\u001b[31mERROR: tensorflow-metadata 0.24.0 has requirement absl-py<0.11,>=0.9, but you'll have absl-py 0.8.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: nbclient 0.5.1 has requirement nbformat>=5.0, but you'll have nbformat 4.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement astor~=0.8.1, but you'll have astor 0.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.17.2, but you'll have google-auth 1.18.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.1.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement notebook~=5.3.0; python_version >= \"3.0\", but you'll have notebook 6.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, absl-py, appnope, astor, attrs, backcall, bleach, decorator, google-auth, google-auth-oauthlib, numpy, Pillow, imageio, more-itertools, zipp, importlib-metadata, python-dateutil, tornado, jupyter-core, pyzmq, jupyter-client, wcwidth, prompt-toolkit, Pygments, pexpect, parso, jedi, ipython, ipykernel, Jinja2, pyrsistent, jsonschema, jupyter-console, PyYAML, Keras-Applications, Keras-Preprocessing, Keras, kiwisolver, Markdown, pyparsing, matplotlib, music21, testpath, pandocfilters, nbformat, nbconvert, networkx, terminado, prometheus-client, notebook, opt-einsum, pytz, pandas, protobuf, pydot, qtconsole, urllib3, requests, scikit-image, Werkzeug, tensorboard, tensorflow-estimator, wrapt, tensorflow, typeguard, tensorflow-addons\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: absl-py 0.10.0\n",
            "    Uninstalling absl-py-0.10.0:\n",
            "      Successfully uninstalled absl-py-0.10.0\n",
            "  Found existing installation: astor 0.8.1\n",
            "    Uninstalling astor-0.8.1:\n",
            "      Successfully uninstalled astor-0.8.1\n",
            "  Found existing installation: attrs 20.2.0\n",
            "    Uninstalling attrs-20.2.0:\n",
            "      Successfully uninstalled attrs-20.2.0\n",
            "  Found existing installation: backcall 0.2.0\n",
            "    Uninstalling backcall-0.2.0:\n",
            "      Successfully uninstalled backcall-0.2.0\n",
            "  Found existing installation: bleach 3.2.1\n",
            "    Uninstalling bleach-3.2.1:\n",
            "      Successfully uninstalled bleach-3.2.1\n",
            "  Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Found existing installation: google-auth 1.17.2\n",
            "    Uninstalling google-auth-1.17.2:\n",
            "      Successfully uninstalled google-auth-1.17.2\n",
            "  Found existing installation: google-auth-oauthlib 0.4.2\n",
            "    Uninstalling google-auth-oauthlib-0.4.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.2\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Found existing installation: more-itertools 8.6.0\n",
            "    Uninstalling more-itertools-8.6.0:\n",
            "      Successfully uninstalled more-itertools-8.6.0\n",
            "  Found existing installation: zipp 3.4.0\n",
            "    Uninstalling zipp-3.4.0:\n",
            "      Successfully uninstalled zipp-3.4.0\n",
            "  Found existing installation: importlib-metadata 2.0.0\n",
            "    Uninstalling importlib-metadata-2.0.0:\n",
            "      Successfully uninstalled importlib-metadata-2.0.0\n",
            "  Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "  Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Found existing installation: jupyter-core 4.6.3\n",
            "    Uninstalling jupyter-core-4.6.3:\n",
            "      Successfully uninstalled jupyter-core-4.6.3\n",
            "  Found existing installation: pyzmq 19.0.2\n",
            "    Uninstalling pyzmq-19.0.2:\n",
            "      Successfully uninstalled pyzmq-19.0.2\n",
            "  Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "  Found existing installation: wcwidth 0.2.5\n",
            "    Uninstalling wcwidth-0.2.5:\n",
            "      Successfully uninstalled wcwidth-0.2.5\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Found existing installation: pexpect 4.8.0\n",
            "    Uninstalling pexpect-4.8.0:\n",
            "      Successfully uninstalled pexpect-4.8.0\n",
            "  Found existing installation: parso 0.7.1\n",
            "    Uninstalling parso-0.7.1:\n",
            "      Successfully uninstalled parso-0.7.1\n",
            "  Found existing installation: jedi 0.17.2\n",
            "    Uninstalling jedi-0.17.2:\n",
            "      Successfully uninstalled jedi-0.17.2\n",
            "  Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "  Found existing installation: Jinja2 2.11.2\n",
            "    Uninstalling Jinja2-2.11.2:\n",
            "      Successfully uninstalled Jinja2-2.11.2\n",
            "  Found existing installation: pyrsistent 0.17.3\n",
            "    Uninstalling pyrsistent-0.17.3:\n",
            "      Successfully uninstalled pyrsistent-0.17.3\n",
            "  Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Found existing installation: jupyter-console 5.2.0\n",
            "    Uninstalling jupyter-console-5.2.0:\n",
            "      Successfully uninstalled jupyter-console-5.2.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "  Found existing installation: kiwisolver 1.3.1\n",
            "    Uninstalling kiwisolver-1.3.1:\n",
            "      Successfully uninstalled kiwisolver-1.3.1\n",
            "  Found existing installation: Markdown 3.3.3\n",
            "    Uninstalling Markdown-3.3.3:\n",
            "      Successfully uninstalled Markdown-3.3.3\n",
            "  Found existing installation: pyparsing 2.4.7\n",
            "    Uninstalling pyparsing-2.4.7:\n",
            "      Successfully uninstalled pyparsing-2.4.7\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: music21 5.5.0\n",
            "    Uninstalling music21-5.5.0:\n",
            "      Successfully uninstalled music21-5.5.0\n",
            "  Found existing installation: testpath 0.4.4\n",
            "    Uninstalling testpath-0.4.4:\n",
            "      Successfully uninstalled testpath-0.4.4\n",
            "  Found existing installation: pandocfilters 1.4.3\n",
            "    Uninstalling pandocfilters-1.4.3:\n",
            "      Successfully uninstalled pandocfilters-1.4.3\n",
            "  Found existing installation: nbformat 5.0.8\n",
            "    Uninstalling nbformat-5.0.8:\n",
            "      Successfully uninstalled nbformat-5.0.8\n",
            "  Found existing installation: nbconvert 5.6.1\n",
            "    Uninstalling nbconvert-5.6.1:\n",
            "      Successfully uninstalled nbconvert-5.6.1\n",
            "  Found existing installation: networkx 2.5\n",
            "    Uninstalling networkx-2.5:\n",
            "      Successfully uninstalled networkx-2.5\n",
            "  Found existing installation: terminado 0.9.1\n",
            "    Uninstalling terminado-0.9.1:\n",
            "      Successfully uninstalled terminado-0.9.1\n",
            "  Found existing installation: prometheus-client 0.8.0\n",
            "    Uninstalling prometheus-client-0.8.0:\n",
            "      Successfully uninstalled prometheus-client-0.8.0\n",
            "  Found existing installation: notebook 5.3.1\n",
            "    Uninstalling notebook-5.3.1:\n",
            "      Successfully uninstalled notebook-5.3.1\n",
            "  Found existing installation: opt-einsum 3.3.0\n",
            "    Uninstalling opt-einsum-3.3.0:\n",
            "      Successfully uninstalled opt-einsum-3.3.0\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pandas 1.1.4\n",
            "    Uninstalling pandas-1.1.4:\n",
            "      Successfully uninstalled pandas-1.1.4\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "  Found existing installation: pydot 1.3.0\n",
            "    Uninstalling pydot-1.3.0:\n",
            "      Successfully uninstalled pydot-1.3.0\n",
            "  Found existing installation: qtconsole 4.7.7\n",
            "    Uninstalling qtconsole-4.7.7:\n",
            "      Successfully uninstalled qtconsole-4.7.7\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "  Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: wrapt 1.12.1\n",
            "    Uninstalling wrapt-1.12.1:\n",
            "      Successfully uninstalled wrapt-1.12.1\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "  Found existing installation: typeguard 2.7.1\n",
            "    Uninstalling typeguard-2.7.1:\n",
            "      Successfully uninstalled typeguard-2.7.1\n",
            "  Found existing installation: tensorflow-addons 0.8.3\n",
            "    Uninstalling tensorflow-addons-0.8.3:\n",
            "      Successfully uninstalled tensorflow-addons-0.8.3\n",
            "Successfully installed Jinja2-2.10.3 Keras-2.3.1 Keras-Applications-1.0.8 Keras-Preprocessing-1.1.0 Markdown-3.1.1 Pillow-6.2.0 PyYAML-5.1.2 Pygments-2.4.2 Werkzeug-0.16.0 absl-py-0.8.1 appnope-0.1.0 astor-0.8.0 attrs-19.2.0 backcall-0.1.0 bleach-3.1.0 decorator-4.4.0 google-auth-1.18.0 google-auth-oauthlib-0.4.1 imageio-2.6.1 importlib-metadata-0.23 ipykernel-5.1.2 ipython-7.8.0 jedi-0.15.1 jsonschema-3.1.1 jupyter-client-5.3.4 jupyter-console-6.0.0 jupyter-core-4.6.0 kiwisolver-1.1.0 matplotlib-3.1.1 more-itertools-7.2.0 music21-5.7.0 nbconvert-5.6.0 nbformat-4.4.0 networkx-2.3 notebook-6.0.1 numpy-1.17.2 opt-einsum-3.1.0 pandas-0.25.1 pandocfilters-1.4.2 parso-0.5.1 pexpect-4.7.0 prometheus-client-0.7.1 prompt-toolkit-2.0.10 protobuf-3.10.0 pydot-1.4.1 pyparsing-2.4.2 pyrsistent-0.15.4 python-dateutil-2.8.0 pytz-2019.3 pyzmq-18.1.0 qtconsole-4.5.5 requests-2.24.0 scikit-image-0.17.2 six-1.12.0 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-addons-0.10.0 tensorflow-estimator-2.2.0 terminado-0.8.2 testpath-0.4.2 tornado-6.0.3 typeguard-2.9.1 urllib3-1.25.9 wcwidth-0.1.7 wrapt-1.11.2 zipp-0.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "PIL",
                  "absl",
                  "astor",
                  "dateutil",
                  "decorator",
                  "google",
                  "imageio",
                  "ipykernel",
                  "jupyter_client",
                  "jupyter_core",
                  "keras_preprocessing",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "opt_einsum",
                  "pandas",
                  "pexpect",
                  "prompt_toolkit",
                  "pygments",
                  "pyparsing",
                  "pytz",
                  "requests",
                  "six",
                  "tensorboard",
                  "tensorflow",
                  "tornado",
                  "urllib3",
                  "wcwidth",
                  "wrapt",
                  "yaml",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akc12158d6wk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZPvWf78dcu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db08a715-63f3-4a6f-bbd6-fb592d5466a7"
      },
      "source": [
        "cd GDL_code/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GDL_code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdYwLTLeENh"
      },
      "source": [
        "## **Autoencoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGkXzqMGdekR",
        "outputId": "37c97882-adcb-48d4-c255-e8bfeef923c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "from utils.loaders import load_mnist\n",
        "from models.AE import Autoencoder"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[autoreload of six failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    del self.failed[py_filename]\n",
            "AttributeError: 'NoneType' object has no attribute 'filter'\n",
            "]\n",
            "[autoreload of IPython.core.ultratb failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    del self.failed[py_filename]\n",
            "AttributeError: module 'IPython' has no attribute 'utils'\n",
            "]\n",
            "[autoreload of pygments failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    del self.failed[py_filename]\n",
            "ImportError: cannot import name 'StringIO'\n",
            "]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_5CflF-eJCx"
      },
      "source": [
        "# **Set parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjKktOWhds1T"
      },
      "source": [
        "# run params\n",
        "SECTION = 'vae'\n",
        "RUN_ID = '0002'\n",
        "DATA_NAME = 'digits'\n",
        "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
        "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
        "\n",
        "if not os.path.exists(RUN_FOLDER):\n",
        "    os.mkdir(RUN_FOLDER)\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
        "\n",
        "MODE =  'build' #'load' #"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLhUPdwdeLwS"
      },
      "source": [
        "# **Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdSltC5Zdysg"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_mnist()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgQx3xt6eWZy"
      },
      "source": [
        "# **Define the structure of the neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5gGaykTeYWC"
      },
      "source": [
        "AE = Autoencoder(\n",
        "    input_dim = (28,28,1)\n",
        "    , encoder_conv_filters = [32,64,64, 64]\n",
        "    , encoder_conv_kernel_size = [3,3,3,3]\n",
        "    , encoder_conv_strides = [1,2,2,1]\n",
        "    , decoder_conv_t_filters = [64,64,32,1]\n",
        "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
        "    , decoder_conv_t_strides = [1,2,2,1]\n",
        "    , z_dim = 2\n",
        ")\n",
        "\n",
        "if MODE == 'build':\n",
        "    AE.save(RUN_FOLDER)\n",
        "else:\n",
        "    AE.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1-uX0TYea7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3cb0c02-1d7f-4c8f-a6a6-26918e32e09a"
      },
      "source": [
        "AE.encoder.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_0 (Conv2D)      (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_1 (Conv2D)      (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_2 (Conv2D)      (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_3 (Conv2D)      (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "encoder_output (Dense)       (None, 2)                 6274      \n",
            "=================================================================\n",
            "Total params: 98,946\n",
            "Trainable params: 98,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axJnE9JLeci9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ca6e7d-394b-4efc-b4f6-aabb46bf0fc6"
      },
      "source": [
        "AE.decoder.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3136)              9408      \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_0 (Conv2DTran (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_1 (Conv2DTran (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_2 (Conv2DTran (None, 28, 28, 32)        18464     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_3 (Conv2DTran (None, 28, 28, 1)         289       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 102,017\n",
            "Trainable params: 102,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJYavCmDewXC"
      },
      "source": [
        "# **Train the autoencoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S5qPO2Ded1T"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "BATCH_SIZE = 32\n",
        "INITIAL_EPOCH = 0"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt8eeI8jfJWH"
      },
      "source": [
        "AE.compile(LEARNING_RATE)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuMxhhQVfKkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fabb0127-1c5a-49c4-b96a-72eedaeb5eb2"
      },
      "source": [
        "AE.train(     \n",
        "    x_train[:1000]\n",
        "    , batch_size = BATCH_SIZE\n",
        "    , epochs = 200\n",
        "    , run_folder = RUN_FOLDER\n",
        "    , initial_epoch = INITIAL_EPOCH\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1709\n",
            "Epoch 00001: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1654\n",
            "Epoch 2/200\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.0756\n",
            "Epoch 00002: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0742\n",
            "Epoch 3/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0666\n",
            "Epoch 00003: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0664\n",
            "Epoch 4/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0615\n",
            "Epoch 00004: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0613\n",
            "Epoch 5/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0588\n",
            "Epoch 00005: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0589\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0571\n",
            "Epoch 00006: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0571\n",
            "Epoch 7/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0555\n",
            "Epoch 00007: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0559\n",
            "Epoch 8/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0551\n",
            "Epoch 00008: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0547\n",
            "Epoch 9/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0539\n",
            "Epoch 00009: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0540\n",
            "Epoch 10/200\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 0.0531\n",
            "Epoch 00010: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0532\n",
            "Epoch 11/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0527\n",
            "Epoch 00011: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0529\n",
            "Epoch 12/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0524\n",
            "Epoch 00012: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0522\n",
            "Epoch 13/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0519\n",
            "Epoch 00013: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0518\n",
            "Epoch 14/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0516\n",
            "Epoch 00014: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0514\n",
            "Epoch 15/200\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 0.0519\n",
            "Epoch 00015: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0511\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0508\n",
            "Epoch 00016: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0508\n",
            "Epoch 17/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0500\n",
            "Epoch 00017: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0505\n",
            "Epoch 18/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0501\n",
            "Epoch 00018: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0501\n",
            "Epoch 19/200\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 0.0492\n",
            "Epoch 00019: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0499\n",
            "Epoch 20/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0496\n",
            "Epoch 00020: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0496\n",
            "Epoch 21/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0494\n",
            "Epoch 00021: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0493\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0490\n",
            "Epoch 00022: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0490\n",
            "Epoch 23/200\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 0.0484\n",
            "Epoch 00023: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0488\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0482\n",
            "Epoch 00024: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0482\n",
            "Epoch 25/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0485\n",
            "Epoch 00025: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0482\n",
            "Epoch 26/200\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 0.0483\n",
            "Epoch 00026: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0483\n",
            "Epoch 27/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0477\n",
            "Epoch 00027: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0477\n",
            "Epoch 28/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0475\n",
            "Epoch 00028: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0475\n",
            "Epoch 29/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0470\n",
            "Epoch 00029: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0473\n",
            "Epoch 30/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0471\n",
            "Epoch 00030: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0472\n",
            "Epoch 31/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0471\n",
            "Epoch 00031: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0470\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0466\n",
            "Epoch 00032: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0466\n",
            "Epoch 33/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0469\n",
            "Epoch 00033: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0464\n",
            "Epoch 34/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0458\n",
            "Epoch 00034: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0463\n",
            "Epoch 35/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0461\n",
            "Epoch 00035: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0461\n",
            "Epoch 36/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0459\n",
            "Epoch 00036: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0459\n",
            "Epoch 37/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0455\n",
            "Epoch 00037: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0457\n",
            "Epoch 38/200\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 0.0453\n",
            "Epoch 00038: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0457\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0456\n",
            "Epoch 00039: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0456\n",
            "Epoch 40/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0450\n",
            "Epoch 00040: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0452\n",
            "Epoch 41/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0448\n",
            "Epoch 00041: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0450\n",
            "Epoch 42/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0454\n",
            "Epoch 00042: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0452\n",
            "Epoch 43/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0447\n",
            "Epoch 00043: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0448\n",
            "Epoch 44/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0444\n",
            "Epoch 00044: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0444\n",
            "Epoch 45/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0440\n",
            "Epoch 00045: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0441\n",
            "Epoch 46/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0439\n",
            "Epoch 00046: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0440\n",
            "Epoch 47/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0444\n",
            "Epoch 00047: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0442\n",
            "Epoch 48/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0445\n",
            "Epoch 00048: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0441\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0438\n",
            "Epoch 00049: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0438\n",
            "Epoch 50/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0436\n",
            "Epoch 00050: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0435\n",
            "Epoch 51/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0432\n",
            "Epoch 00051: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0433\n",
            "Epoch 52/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0435\n",
            "Epoch 00052: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0433\n",
            "Epoch 53/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0433\n",
            "Epoch 00053: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0429\n",
            "Epoch 54/200\n",
            "23/32 [====================>.........] - ETA: 0s - loss: 0.0436\n",
            "Epoch 00054: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0428\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0429\n",
            "Epoch 00055: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0429\n",
            "Epoch 56/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0428\n",
            "Epoch 00056: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0428\n",
            "Epoch 57/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0434\n",
            "Epoch 00057: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0431\n",
            "Epoch 58/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0427\n",
            "Epoch 00058: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0425\n",
            "Epoch 59/200\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.0419\n",
            "Epoch 00059: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0422\n",
            "Epoch 60/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0422\n",
            "Epoch 00060: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0421\n",
            "Epoch 61/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0424\n",
            "Epoch 00061: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0424\n",
            "Epoch 62/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0420\n",
            "Epoch 00062: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0421\n",
            "Epoch 63/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0415\n",
            "Epoch 00063: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0417\n",
            "Epoch 64/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0415\n",
            "Epoch 00064: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0416\n",
            "Epoch 65/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0415\n",
            "Epoch 00065: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0413\n",
            "Epoch 66/200\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.0411\n",
            "Epoch 00066: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0414\n",
            "Epoch 67/200\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.0415\n",
            "Epoch 00067: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0415\n",
            "Epoch 68/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0416\n",
            "Epoch 00068: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0416\n",
            "Epoch 69/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0412\n",
            "Epoch 00069: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0413\n",
            "Epoch 70/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0413\n",
            "Epoch 00070: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0414\n",
            "Epoch 71/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0407\n",
            "Epoch 00071: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0410\n",
            "Epoch 72/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0404\n",
            "Epoch 00072: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0407\n",
            "Epoch 73/200\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.0408\n",
            "Epoch 00073: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0407\n",
            "Epoch 74/200\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.0413\n",
            "Epoch 00074: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0408\n",
            "Epoch 75/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0409\n",
            "Epoch 00075: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0409\n",
            "Epoch 76/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0407\n",
            "Epoch 00076: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0408\n",
            "Epoch 77/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0403\n",
            "Epoch 00077: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0403\n",
            "Epoch 78/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0404\n",
            "Epoch 00078: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0404\n",
            "Epoch 79/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0402\n",
            "Epoch 00079: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0403\n",
            "Epoch 80/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0396\n",
            "Epoch 00080: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0400\n",
            "Epoch 81/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0400\n",
            "Epoch 00081: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0400\n",
            "Epoch 82/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0404\n",
            "Epoch 00082: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0404\n",
            "Epoch 83/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0401\n",
            "Epoch 00083: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0401\n",
            "Epoch 84/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0397\n",
            "Epoch 00084: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0397\n",
            "Epoch 85/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0395\n",
            "Epoch 00085: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0395\n",
            "Epoch 86/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0397\n",
            "Epoch 00086: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0396\n",
            "Epoch 87/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0396\n",
            "Epoch 00087: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0397\n",
            "Epoch 88/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0394\n",
            "Epoch 00088: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0392\n",
            "Epoch 89/200\n",
            "24/32 [=====================>........] - ETA: 0s - loss: 0.0395\n",
            "Epoch 00089: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0391\n",
            "Epoch 90/200\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.0392\n",
            "Epoch 00090: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0392\n",
            "Epoch 91/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0392\n",
            "Epoch 00091: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0390\n",
            "Epoch 92/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0384\n",
            "Epoch 00092: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0389\n",
            "Epoch 93/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0391\n",
            "Epoch 00093: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0391\n",
            "Epoch 94/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0389\n",
            "Epoch 00094: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0389\n",
            "Epoch 95/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0388\n",
            "Epoch 00095: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0389\n",
            "Epoch 96/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0390\n",
            "Epoch 00096: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0389\n",
            "Epoch 97/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0395\n",
            "Epoch 00097: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0392\n",
            "Epoch 98/200\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.0389\n",
            "Epoch 00098: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0388\n",
            "Epoch 99/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0386\n",
            "Epoch 00099: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0385\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0392\n",
            "Epoch 00100: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0392\n",
            "Epoch 101/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0384\n",
            "Epoch 00101: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0384\n",
            "Epoch 102/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0387\n",
            "Epoch 00102: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0384\n",
            "Epoch 103/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0389\n",
            "Epoch 00103: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0388\n",
            "Epoch 104/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0385\n",
            "Epoch 00104: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0383\n",
            "Epoch 105/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0381\n",
            "Epoch 00105: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0381\n",
            "Epoch 106/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0387\n",
            "Epoch 00106: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0386\n",
            "Epoch 107/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0389\n",
            "Epoch 00107: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0388\n",
            "Epoch 108/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0379\n",
            "Epoch 00108: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0380\n",
            "Epoch 109/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0378\n",
            "Epoch 00109: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0378\n",
            "Epoch 110/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0378\n",
            "Epoch 00110: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0377\n",
            "Epoch 111/200\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.0373\n",
            "Epoch 00111: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0378\n",
            "Epoch 112/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0377\n",
            "Epoch 00112: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0380\n",
            "Epoch 113/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0376\n",
            "Epoch 00113: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0376\n",
            "Epoch 114/200\n",
            "22/32 [===================>..........] - ETA: 0s - loss: 0.0377\n",
            "Epoch 00114: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0376\n",
            "Epoch 115/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0374\n",
            "Epoch 00115: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0375\n",
            "Epoch 116/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0373\n",
            "Epoch 00116: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0374\n",
            "Epoch 117/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0375\n",
            "Epoch 00117: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0375\n",
            "Epoch 118/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0375\n",
            "Epoch 00118: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0374\n",
            "Epoch 119/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0374\n",
            "Epoch 00119: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0374\n",
            "Epoch 120/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0373\n",
            "Epoch 00120: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0373\n",
            "Epoch 121/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0373\n",
            "Epoch 00121: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0373\n",
            "Epoch 122/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0373\n",
            "Epoch 00122: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0373\n",
            "Epoch 123/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0368\n",
            "Epoch 00123: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0372\n",
            "Epoch 124/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0371\n",
            "Epoch 00124: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0369\n",
            "Epoch 125/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0371\n",
            "Epoch 00125: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0371\n",
            "Epoch 126/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0372\n",
            "Epoch 00126: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0372\n",
            "Epoch 127/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0363\n",
            "Epoch 00127: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0367\n",
            "Epoch 128/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0368\n",
            "Epoch 00128: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0368\n",
            "Epoch 129/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0370\n",
            "Epoch 00129: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0371\n",
            "Epoch 130/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0369\n",
            "Epoch 00130: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0369\n",
            "Epoch 131/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0366\n",
            "Epoch 00131: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0367\n",
            "Epoch 132/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0368\n",
            "Epoch 00132: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0369\n",
            "Epoch 133/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0368\n",
            "Epoch 00133: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0368\n",
            "Epoch 134/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0370\n",
            "Epoch 00134: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0369\n",
            "Epoch 135/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0367\n",
            "Epoch 00135: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0366\n",
            "Epoch 136/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0364\n",
            "Epoch 00136: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0364\n",
            "Epoch 137/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0368\n",
            "Epoch 00137: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0366\n",
            "Epoch 138/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0369\n",
            "Epoch 00138: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0369\n",
            "Epoch 139/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0373\n",
            "Epoch 00139: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0371\n",
            "Epoch 140/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0370\n",
            "Epoch 00140: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0368\n",
            "Epoch 141/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0360\n",
            "Epoch 00141: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0361\n",
            "Epoch 142/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0364\n",
            "Epoch 00142: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0363\n",
            "Epoch 143/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0363\n",
            "Epoch 00143: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0364\n",
            "Epoch 144/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0361\n",
            "Epoch 00144: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0363\n",
            "Epoch 145/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0363\n",
            "Epoch 00145: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0364\n",
            "Epoch 146/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0366\n",
            "Epoch 00146: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0365\n",
            "Epoch 147/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0362\n",
            "Epoch 00147: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0363\n",
            "Epoch 148/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0363\n",
            "Epoch 00148: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0363\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0360\n",
            "Epoch 00149: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0360\n",
            "Epoch 150/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0363\n",
            "Epoch 00150: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0362\n",
            "Epoch 151/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0361\n",
            "Epoch 00151: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0361\n",
            "Epoch 152/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0360\n",
            "Epoch 00152: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0360\n",
            "Epoch 153/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0361\n",
            "Epoch 00153: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0361\n",
            "Epoch 154/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0359\n",
            "Epoch 00154: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0359\n",
            "Epoch 155/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00155: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0358\n",
            "Epoch 156/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0361\n",
            "Epoch 00156: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0360\n",
            "Epoch 157/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0357\n",
            "Epoch 00157: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0358\n",
            "Epoch 158/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0358\n",
            "Epoch 00158: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0358\n",
            "Epoch 159/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0358\n",
            "Epoch 00159: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0357\n",
            "Epoch 160/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0363\n",
            "Epoch 00160: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0362\n",
            "Epoch 161/200\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.0365\n",
            "Epoch 00161: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0364\n",
            "Epoch 162/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00162: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0356\n",
            "Epoch 163/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0360\n",
            "Epoch 00163: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0360\n",
            "Epoch 164/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00164: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0356\n",
            "Epoch 165/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00165: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0356\n",
            "Epoch 166/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0353\n",
            "Epoch 00166: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0352\n",
            "Epoch 167/200\n",
            "24/32 [=====================>........] - ETA: 0s - loss: 0.0358\n",
            "Epoch 00167: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0357\n",
            "Epoch 168/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0357\n",
            "Epoch 00168: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0355\n",
            "Epoch 169/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00169: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0358\n",
            "Epoch 170/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0354\n",
            "Epoch 00170: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0354\n",
            "Epoch 171/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0357\n",
            "Epoch 00171: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0356\n",
            "Epoch 172/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0354\n",
            "Epoch 00172: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0354\n",
            "Epoch 173/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00173: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0353\n",
            "Epoch 174/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0351\n",
            "Epoch 00174: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0351\n",
            "Epoch 175/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00175: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0352\n",
            "Epoch 176/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00176: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0353\n",
            "Epoch 177/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0350\n",
            "Epoch 00177: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0352\n",
            "Epoch 178/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0354\n",
            "Epoch 00178: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0353\n",
            "Epoch 179/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0349\n",
            "Epoch 00179: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0352\n",
            "Epoch 180/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0350\n",
            "Epoch 00180: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0352\n",
            "Epoch 181/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0359\n",
            "Epoch 00181: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0356\n",
            "Epoch 182/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0352\n",
            "Epoch 00182: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0353\n",
            "Epoch 183/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0354\n",
            "Epoch 00183: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0353\n",
            "Epoch 184/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0351\n",
            "Epoch 00184: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0351\n",
            "Epoch 185/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0351\n",
            "Epoch 00185: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0353\n",
            "Epoch 186/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0352\n",
            "Epoch 00186: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0352\n",
            "Epoch 187/200\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.0347\n",
            "Epoch 00187: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0349\n",
            "Epoch 188/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0348\n",
            "Epoch 00188: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0349\n",
            "Epoch 189/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0348\n",
            "Epoch 00189: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0348\n",
            "Epoch 190/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0348\n",
            "Epoch 00190: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0347\n",
            "Epoch 191/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0350\n",
            "Epoch 00191: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0349\n",
            "Epoch 192/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0349\n",
            "Epoch 00192: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0349\n",
            "Epoch 193/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0347\n",
            "Epoch 00193: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0347\n",
            "Epoch 194/200\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0347\n",
            "Epoch 00194: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0348\n",
            "Epoch 195/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0346\n",
            "Epoch 00195: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0347\n",
            "Epoch 196/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0347\n",
            "Epoch 00196: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0348\n",
            "Epoch 197/200\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00197: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0351\n",
            "Epoch 198/200\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.0350\n",
            "Epoch 00198: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0349\n",
            "Epoch 199/200\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.0351\n",
            "Epoch 00199: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0350\n",
            "Epoch 200/200\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.0347\n",
            "Epoch 00200: saving model to run/vae/0002_digits/weights/weights.h5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTg3e3-cyXX0"
      },
      "source": [
        "# **VAE Analysis**\n",
        "## **imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT4eiWTsyGi2",
        "outputId": "f4f3ae10-dd9d-4adf-cc5d-b9c14924cb8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhDoZfaoyhxW",
        "outputId": "3c4e3a10-4f54-40c8-dd95-5d593a8b9cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.stats import norm\n",
        "\n",
        "from models.VAE import VariationalAutoencoder\n",
        "from utils.loaders import load_mnist, load_model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9dfc4b29a6e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAE\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariationalAutoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvd7n2EwzlRp"
      },
      "source": [
        "## **imports**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzEv1k3hz8yv"
      },
      "source": [
        "## **architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ogrPVnWz70B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "af21b725-fa4e-4981-c994-da4bddd7e1a7"
      },
      "source": [
        "vae = load_model(VariationalAutoencoder, RUN_FOLDER)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2ab977dbe975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariationalAutoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRzDl2NezkHo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}